# -*- coding: utf-8 -*-
"""task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gCzKtn4geuk3pd6ek1rl7ry1Ho9Wioqk
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Load Iris dataset
iris = load_iris()
df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
df['species'] = iris.target
df['species'] = df['species'].map({0:'setosa', 1:'versicolor', 2:'virginica'})

# Display the first 5 rows
print("üîç First 5 rows of the dataset:")
print(df.head())

# Check for missing values
print("\nüßº Checking for missing values:")
print(df.isnull().sum())

# Visualize the data
sns.pairplot(df, hue='species')
plt.suptitle("Pair Plot of Iris Features", y=1.02)
plt.show()

# Splitting features and target
X = df.drop('species', axis=1)
y = df['species']

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Create k-NN model (k=3)
model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train_scaled, y_train)

# Make predictions
y_pred = model.predict(X_test_scaled)

# Evaluation
print("\n‚úÖ Classification Report:")
print(classification_report(y_test, y_pred))

print("üìä Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("üéØ Accuracy Score:", accuracy_score(y_test, y_pred))